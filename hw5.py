import pathlib
from typing import Union, Tuple
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import json

class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    """

    def __init__(self, data_fname: Union[pathlib.Path, str]):
        """
        Initializes the QuestionnaireAnalysis object with the given data file name.

        :param data_fname: The path to the JSON file containing questionnaire data.
        """
        self.data_fname = pathlib.Path(data_fname)
        self.data = None  # Will hold the DataFrame
        self.raw_data = None  # Will hold raw JSON data
        self.validate_file()

    def validate_file(self):
        """Validates the file existence and format."""
        if not self.data_fname.exists():
            raise ValueError(f"Data file {self.data_fname} does not exist.")

    def read_data(self):
        """Reads and validates the JSON data into a DataFrame."""
        try:
            with self.data_fname.open('r', encoding='utf-8') as file:
                self.raw_data = json.load(file)
        except json.JSONDecodeError as e:
            raise ValueError(f"The file {self.data_fname} is not valid JSON: {e}")

        if not isinstance(self.raw_data, list):
            raise ValueError("Data should be a list of dictionaries.")

        self.data = pd.DataFrame(self.raw_data)

        # Replace "nan" strings with actual NaN values
        self.data.replace("nan", pd.NA, inplace=True)

        # Expected column headers
        headers = ["id", "first_name", "last_name", "email", "timestamp",
               "age", "gender", "q1", "q2", "q3", "q4", "q5"]

        # Enforce column headers
        if list(self.data.columns) != headers:
            self.data.columns = headers

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        """Calculates and plots the age distribution of the participants.

        Returns
        -------
        hist : np.ndarray
        Number of people in a given bin
        bins : np.ndarray
        Bin edges
       """
        if self.data is None or 'age' not in self.data.columns:
            raise ValueError("Data not loaded or 'Age' column missing.")
        
        # Convert age to numeric, coercing errors to NaN
        ages = pd.to_numeric(self.data['age'], errors='coerce').dropna()
        
        # Calculate histogram with 10 bins: [0,10), [10,20), ..., [90,100]
        bins = np.arange(0, 101, 10)
        hist, bins = np.histogram(ages, bins=bins)
        
        
        # Plotting the histogram
        plt.figure(figsize=(10, 6))
        plt.hist(ages, bins=bins, edgecolor='black', alpha=0.7)
        plt.title('Age Distribution of Participants')
        plt.xlabel('Age')
        plt.ylabel('Number of Participants')
        plt.grid(axis='y', alpha=0.75)
        plt.show()
        
        return hist, bins
    
    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

        Returns
        -------
        df : pd.DataFrame
        A corrected DataFrame, i.e., the same table but with the erroneous rows removed and
        the (ordinal) index after a reset.
        """
        def is_valid_email(email):
            if not isinstance(email, str):
                return False
            if email.startswith('@') or email.endswith('@'):
                return False
            if email.startswith('.') or email.endswith('.'):
                return False
            if email.count('@') != 1:
                return False
            if '.' not in email:
                return False
            at_index = email.index('@')
            # The character after "@" must not be "."
            if at_index + 1 < len(email) and email[at_index + 1] == '.':
                return False
            # Check structure: <chars>@<chars>.<chars>
            local, sep, domain = email.partition('@')
            if not local or not domain or sep != '@':
                return False
            domain_name, dot, tld = domain.partition('.')
            if not domain_name or not tld or dot != '.':
                return False
            return True

        df = self.data.copy()
        mask = df['email'].apply(is_valid_email)  # Use the correct column name
        df = df[mask].reset_index(drop=True)
        return df
    
    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

        Returns
        -------
        df : pd.DataFrame
          The corrected DataFrame after insertion of the mean grade
        arr : np.ndarray
          Row indices of the students that their new grades were generated
        """
        # List of question columns
        question_cols = ["q1", "q2", "q3", "q4", "q5"]
        df = self.data.copy()
        # Track indices of rows that were corrected
        corrected_indices = []

        for idx, row in df.iterrows():
            # Get the grades for the questions
            grades = row[question_cols]
            # Find which are missing (NA)
            na_mask = grades.isna()
            if na_mask.any():
                # Only fill if not all are NA
                if na_mask.sum() < len(question_cols):
                    mean_grade = grades[~na_mask].astype(float).mean()
                    # Fill only the missing values with the mean
                    for col in grades.index[na_mask]:
                        df.at[idx, col] = mean_grade
                    corrected_indices.append(idx)

        return df, np.array(corrected_indices)
    
    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score is UInt8, and the floating point raw numbers should be
        rounded down.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """
        question_cols = ["q1", "q2", "q3", "q4", "q5"]
        scores = []

        for _, row in self.data.iterrows():
            grades = row[question_cols]
            n_nans = grades.isna().sum()
            if n_nans > maximal_nans_per_sub:
                scores.append(pd.NA)
            else:
                mean_score = np.floor(pd.to_numeric(grades, errors='coerce').dropna().mean())
                if np.isnan(mean_score):
                    scores.append(pd.NA)
                else:
                    scores.append(int(mean_score))

        self.data["score"] = pd.Series(scores, dtype="UInt8")
        return self.data
    
    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

        Returns
        -------
        pd.DataFrame
            A DataFrame with a MultiIndex containing the gender and whether the subject is above
            40 years of age, and the average score in each of the five questions.
        """
        df = self.raw_data.copy()
        df["age"] = pd.to_numeric(df["age"], errors="coerce")
        df["age"] = df["age"] > 40
        # Ensure question columns are numeric
        for col in ["q1", "q2", "q3", "q4", "q5"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        grouped = df.groupby(["gender", "age"])[["q1", "q2", "q3", "q4", "q5"]].mean()
        grouped = grouped.astype("float64")
        return grouped