import pathlib
from typing import Tuple, Union

from matplotlib import pyplot as plt
import numpy as np
import pandas as pd


class QuestionnaireAnalysis:
    """
    Reads and analyzes data generated by the questionnaire experiment.
    Should be able to accept strings and pathlib.Path objects.
    """

    def __init__(self, data_fname: Union[pathlib.Path, str]):
        if not isinstance(data_fname, pathlib.Path) and not isinstance(data_fname, str):
            raise TypeError(f"Type must be either pathlib.Path or str but got {type(data_fname)}.")
                    
        self.data_fname = pathlib.Path(data_fname)
        if not self.data_fname.exists():
            raise ValueError(f"The given path: \"{data_fname}\" doesn't exist.")

    def read_data(self):
        """Reads the json data located in self.data_fname into memory, to
        the attribute self.data.
        """
        self.data = pd.read_json(self.data_fname)

    def show_age_distrib(self) -> Tuple[np.ndarray, np.ndarray]:
        """Calculates and plots the age distribution of the participants.

    Returns
    -------
    hist : np.ndarray
    Number of people in a given bin
    bins : np.ndarray
    Bin edges
        """
        bins = np.linspace(0, 100, 11)
        _, ax = plt.subplots()
        hist, bin_edges, _ = ax.hist(self.data["age"], bins=bins)
        ax.set_title("Ages distribution")
        ax.set_xlabel("Ages")
        ax.set_ylabel("Amount in bins")

        return hist, bin_edges
    
    def _is_valid_email(self, email: str) -> bool:
        # Must have
        if not isinstance(email, str):
            return False
        if email.count("@") != 1:
            return False
        if email.startswith("@") or email.endswith("@"):
            return False
        if "." not in email:
            return False
        if email.startswith(".") or email.endswith("."):
            return False
        
        # The additional checks I've added (except `domain.startswith(".")` which is a must).
        local, domain = email.split("@")
        if not local or not domain:
            return False
        if domain.startswith(".") or domain.endswith("."):
            return False
        if " " in email:
            return False 
        return True


    def remove_rows_without_mail(self) -> pd.DataFrame:
        """Checks self.data for rows with invalid emails, and removes them.

    Returns
    -------
    df : pd.DataFrame
    A corrected DataFrame, i.e. the same table but with the erroneous rows removed and
    the (ordinal) index after a reset.
        """
        mask = self.data["email"].apply(lambda email: self._is_valid_email(email))
        return self.data.loc[mask].reset_index(drop=True)
    
    def fill_na_with_mean(self) -> Tuple[pd.DataFrame, np.ndarray]:
        """Finds, in the original DataFrame, the subjects that didn't answer
        all questions, and replaces that missing value with the mean of the
        other grades for that student.

    Returns
    -------
    df : pd.DataFrame
    The corrected DataFrame after insertion of the mean grade
    arr : np.ndarray
        Row indices of the students that their new grades were generated
        """
        df = self.data.copy()
        question_cols = ["q1", "q2", "q3", "q4", "q5"]
        # Convert `nan` strings to `np.nan` values so we can work with np.
        df[question_cols] = df[question_cols].replace("nan", np.nan).astype(float)
        corrected_indices = []
        for idx, row in df.iterrows():
            row_values = row[question_cols]
            if row_values.isna().any():
                mean_val = row_values.mean(skipna=True)
                df.loc[idx, question_cols] = row_values.fillna(mean_val)
                corrected_indices.append(idx)

        return df, np.array(corrected_indices)
    
    def score_subjects(self, maximal_nans_per_sub: int = 1) -> pd.DataFrame:
        """Calculates the average score of a subject and adds a new "score" column
        with it.

        If the subject has more than "maximal_nans_per_sub" NaN in his grades, the
        score should be NA. Otherwise, the score is simply the mean of the other grades.
        The datatype of score is UInt8, and the floating point raw numbers should be
        rounded down.

        Parameters
        ----------
        maximal_nans_per_sub : int, optional
            Number of allowed NaNs per subject before giving a NA score.

        Returns
        -------
        pd.DataFrame
            A new DF with a new column - "score".
        """
        question_cols = ["q1", "q2", "q3", "q4", "q5"]

        # Convert `nan` strings to `np.nan` values so we can work with np.
        self.data[question_cols] = self.data[question_cols].replace("nan", np.nan)
        n_nans = self.data[question_cols].isna().sum(axis=1)
        row_means = self.data[question_cols].mean(axis=1, skipna=True).apply(np.floor)
        # We first create a column which is all just `np.NA`, and later will replace the 
        # specific rows we need.
        score_col = pd.Series([pd.NA] * len(self.data), index=self.data.index, dtype="UInt8")
        valid_mask = n_nans <= maximal_nans_per_sub
        # Now we replace only the rows that satisfy the `maximal_nans_per_sub` condition.
        score_col[valid_mask] = row_means[valid_mask].astype("UInt8")
        self.data["score"] = score_col

        return self.data
    
    def correlate_gender_age(self) -> pd.DataFrame:
        """Looks for a correlation between the gender of the subject, their age
        and the score for all five questions.

    Returns
    -------
    pd.DataFrame
        A DataFrame with a MultiIndex containing the gender and whether the subject is above
        40 years of age, and the average score in each of the five questions.
    """
        df = self.data.copy()
        df = df.dropna(subset=["age"])
        df["age"] = df["age"]
        # We override the age row with a boolean which we will use later to group by 
        # whether the age condition is satisfied or not. Now that we will have this 
        # boolean, we can just do a simple `groupby` and we will group by the `< 40` 
        # condition (in addition to the "gender").
        df["age"] = df["age"] > 40  
        grouped = df.groupby(["gender", "age"])[["q1", "q2", "q3", "q4", "q5"]].mean()
        return grouped
    
if __name__ == "__main__":
    a = QuestionnaireAnalysis("./data.json")
    a.read_data()
    a.correlate_gender_age()



        
